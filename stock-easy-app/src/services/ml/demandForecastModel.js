/**
 * Mod√®le de pr√©vision de demande avec TensorFlow.js
 * @module services/ml/demandForecastModel
 */

import * as tf from '@tensorflow/tfjs';
import { DataValidator } from '@/utils/ml/dataValidator';
import { 
  DataValidationError, 
  ModelTrainingError,
  MLErrorHandler 
} from '@/utils/ml/mlErrors';

export class DemandForecastModel {
  constructor() {
    this.model = null;
    this.featureStats = null; // Pour la normalisation
  }

  /**
   * Cr√©e l'architecture du r√©seau de neurones
   * @private
   */
  createModel() {
    const model = tf.sequential({
      layers: [
        // Couche d'entr√©e + premi√®re couche cach√©e
        tf.layers.dense({
          inputShape: [6],
          units: 32,
          activation: 'relu',
          kernelInitializer: 'heNormal'
        }),
        
        // Dropout pour √©viter l'overfitting
        tf.layers.dropout({ rate: 0.2 }),
        
        // Deuxi√®me couche cach√©e
        tf.layers.dense({
          units: 16,
          activation: 'relu',
          kernelInitializer: 'heNormal'
        }),
        
        // Dropout
        tf.layers.dropout({ rate: 0.1 }),
        
        // Troisi√®me couche cach√©e
        tf.layers.dense({
          units: 8,
          activation: 'relu',
          kernelInitializer: 'heNormal'
        }),
        
        // Couche de sortie (quantit√© pr√©dite)
        tf.layers.dense({
          units: 1,
          activation: 'linear' // Pas d'activation pour r√©gression
        })
      ]
    });

    // Compiler le mod√®le
    model.compile({
      optimizer: tf.train.adam(0.001), // Learning rate
      loss: 'meanSquaredError',
      metrics: ['mae'] // Mean Absolute Error
    });

    return model;
  }

  /**
   * Normalise les features pour am√©liorer l'entra√Ænement
   * @private
   */
  normalizeFeatures(features, stats = null) {
    // Si pas de stats, calculer depuis les donn√©es
    if (!stats) {
      const tensor = tf.tensor2d(features);
      const mean = tensor.mean(0);
      const std = tf.moments(tensor, 0).variance.sqrt();
      
      stats = {
        mean: mean.arraySync(),
        std: std.arraySync()
      };
      
      tensor.dispose();
      mean.dispose();
      std.dispose();
    }
    
    // Normaliser: (x - mean) / std
    const normalized = features.map(feature => 
      feature.map((val, idx) => 
        (val - stats.mean[idx]) / (stats.std[idx] + 1e-7) // +epsilon pour √©viter division par 0
      )
    );
    
    return { normalized, stats };
  }

  /**
   * Pr√©pare les donn√©es pour l'entra√Ænement
   * @private
   */
  prepareTrainingData(salesHistory) {
    console.log(`üìä Pr√©paration de ${salesHistory.length} enregistrements...`);
    
    // Regrouper par SKU pour calculer la moyenne des ventes
    const skuAvg = {};
    salesHistory.forEach(sale => {
      if (!skuAvg[sale.sku]) {
        skuAvg[sale.sku] = { sum: 0, count: 0 };
      }
      skuAvg[sale.sku].sum += sale.quantity;
      skuAvg[sale.sku].count += 1;
    });
    
    // Calculer les moyennes
    Object.keys(skuAvg).forEach(sku => {
      skuAvg[sku] = skuAvg[sku].sum / skuAvg[sku].count;
    });
    
    // Cr√©er les features et labels
    const features = salesHistory.map(sale => [
      sale.dayOfWeek,           // 0-6
      sale.month,               // 1-12
      sale.isWeekend ? 1 : 0,   // 0 ou 1
      sale.isHoliday ? 1 : 0,   // 0 ou 1
      sale.price,               // Prix de vente
      skuAvg[sale.sku] || 0     // Moyenne des ventes pour ce SKU
    ]);
    
    const labels = salesHistory.map(sale => sale.quantity);
    
    return { features, labels };
  }

  /**
   * Entra√Æne le mod√®le sur l'historique des ventes
   * @param {Array} salesHistory - Historique des ventes
   * @param {Object} options - Options d'entra√Ænement
   * @returns {Promise<Object>} Historique d'entra√Ænement
   */
  async train(salesHistory, options = {}) {
    return MLErrorHandler.wrap(async () => {
      const {
        epochs = 50, // R√©duit de 100 √† 50 (early stopping g√©rera le reste)
        batchSize = 32,
        validationSplit = 0.2,
        verbose = 1,
        minRecords = 50,
        maxZScore = 3,
        minCV = 0.05,
        maxGapDays = 7,
        earlyStopping = true,
        patience = 10, // Arr√™ter si pas d'am√©lioration depuis 10 epochs
        minDelta = 0.001 // Am√©lioration minimum pour consid√©rer comme progr√®s
      } = options;

      console.log('üöÄ D√©but de l\'entra√Ænement du mod√®le ML...');
      console.log(`üìä Donn√©es: ${salesHistory.length} enregistrements`);
      console.log(`‚öôÔ∏è Param√®tres: ${epochs} epochs, batch size ${batchSize}`);

      // ========================================
      // √âTAPE 1: VALIDATION DES DONN√âES
      // ========================================
      
      console.log('üîç Validation des donn√©es...');

      const validation = DataValidator.validateSalesHistory(salesHistory, {
        minRecords,
        maxZScore,
        minCV,
        maxGapDays
      });

      // Afficher le rapport de validation (en dev)
      if (import.meta.env.DEV) {
        console.log(DataValidator.formatValidationReport(validation));
      }

      // Si erreurs critiques, on arr√™te
      if (!validation.valid) {
        throw new DataValidationError(
          'Les donn√©es ne sont pas valides pour l\'entra√Ænement',
          validation
        );
      }

      // Si avertissements, on log mais on continue
      if (validation.warnings.length > 0) {
        console.warn(
          `‚ö†Ô∏è  ${validation.warnings.length} avertissement(s):`,
          validation.warnings
        );
      }

      console.log('‚úÖ Validation r√©ussie!');
      console.log('üìä Statistiques:', validation.stats);

      // ========================================
      // √âTAPE 2: PR√âPARATION DES DONN√âES
      // ========================================

      // Pr√©parer les donn√©es
      const { features, labels } = this.prepareTrainingData(salesHistory);
      
      // Normaliser les features
      const { normalized, stats } = this.normalizeFeatures(features);
      this.featureStats = stats;
      
      // Cr√©er le mod√®le
      this.model = this.createModel();
      
      // Afficher l'architecture
      console.log('üèóÔ∏è Architecture du mod√®le:');
      this.model.summary();
      
      // Convertir en tenseurs
      const xs = tf.tensor2d(normalized);
      const ys = tf.tensor2d(labels, [labels.length, 1]);
      
      // Early stopping tracking
      let bestValLoss = Infinity;
      let patienceCounter = 0;
      let stoppedEarly = false;
      let actualEpochs = 0;
      
      // Entra√Æner
      const history = await this.model.fit(xs, ys, {
        epochs,
        batchSize,
        validationSplit,
        verbose,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            actualEpochs = epoch + 1;
            
            // Early stopping logic
            if (earlyStopping && logs.val_loss !== undefined) {
              const improvement = bestValLoss - logs.val_loss;
              
              if (improvement > minDelta) {
                // Am√©lioration significative
                bestValLoss = logs.val_loss;
                patienceCounter = 0;
              } else {
                // Pas d'am√©lioration
                patienceCounter++;
                
                if (patienceCounter >= patience) {
                  stoppedEarly = true;
                  console.log(`üõë Early stopping at epoch ${actualEpochs}/${epochs} (val_loss: ${logs.val_loss.toFixed(4)})`);
                  // Note: TensorFlow.js ne supporte pas l'arr√™t direct, mais on log pour info
                }
              }
            }
            
            if (epoch % 10 === 0 || stoppedEarly) {
              console.log(
                `Epoch ${actualEpochs}/${epochs} - ` +
                `loss: ${logs.loss.toFixed(4)} - ` +
                `mae: ${logs.mae.toFixed(4)} - ` +
                `val_loss: ${logs.val_loss.toFixed(4)} - ` +
                `val_mae: ${logs.val_mae.toFixed(4)}` +
                (stoppedEarly ? ' [EARLY STOP]' : '')
              );
            }
          }
        }
      });
      
      // Nettoyer les tenseurs
      xs.dispose();
      ys.dispose();
      
      if (stoppedEarly) {
        console.log(`‚úÖ Entra√Ænement termin√© avec early stopping (${actualEpochs}/${epochs} epochs)`);
      } else {
        console.log('‚úÖ Entra√Ænement termin√©!');
      }
      
      // Retourner l'historique avec les informations de validation
      return {
        history,
        validation: {
          stats: validation.stats,
          warnings: validation.warnings
        },
        trainingInfo: {
          actualEpochs,
          stoppedEarly,
          bestValLoss
        }
      };
    }, {
      operation: 'train',
      modelName: 'DemandForecastModel'
    });
  }

  /**
   * Pr√©dit la quantit√© pour des features donn√©es
   * @param {Object} features - Features de pr√©diction
   * @returns {Promise<number>} Quantit√© pr√©dite
   */
  async predict(features) {
    if (!this.model) {
      throw new Error('Le mod√®le n\'est pas entra√Æn√©. Appelez train() d\'abord.');
    }

    // Pr√©parer les features
    const featureArray = [
      features.dayOfWeek,
      features.month,
      features.isWeekend ? 1 : 0,
      features.isHoliday ? 1 : 0,
      features.price,
      features.avgSales
    ];
    
    // Normaliser avec les stats d'entra√Ænement
    const normalized = featureArray.map((val, idx) => 
      (val - this.featureStats.mean[idx]) / (this.featureStats.std[idx] + 1e-7)
    );
    
    // Pr√©dire
    const inputTensor = tf.tensor2d([normalized]);
    const prediction = this.model.predict(inputTensor);
    const value = await prediction.data();
    
    // Nettoyer
    inputTensor.dispose();
    prediction.dispose();
    
    // Retourner valeur positive arrondie
    return Math.max(0, Math.round(value[0]));
  }

  /**
   * Pr√©dit en batch pour plusieurs features (BEAUCOUP plus rapide)
   * @param {Array<Object>} featuresArray - Tableau de features
   * @returns {Promise<Array<number>>} Tableau de quantit√©s pr√©dites
   */
  async predictBatch(featuresArray) {
    if (!this.model) {
      throw new Error('Le mod√®le n\'est pas entra√Æn√©. Appelez train() d\'abord.');
    }

    if (!Array.isArray(featuresArray) || featuresArray.length === 0) {
      return [];
    }

    try {
      // Pr√©parer toutes les features
      const normalizedBatch = featuresArray.map(features => {
        const featureArray = [
          features.dayOfWeek,
          features.month,
          features.isWeekend ? 1 : 0,
          features.isHoliday ? 1 : 0,
          features.price,
          features.avgSales
        ];
        
        // Normaliser avec les stats d'entra√Ænement
        return featureArray.map((val, idx) => 
          (val - this.featureStats.mean[idx]) / (this.featureStats.std[idx] + 1e-7)
        );
      });
      
      // Pr√©dire en batch (une seule passe TensorFlow)
      const inputTensor = tf.tensor2d(normalizedBatch);
      const predictions = this.model.predict(inputTensor);
      const values = await predictions.data();
      
      // Nettoyer
      inputTensor.dispose();
      predictions.dispose();
      
      // Convertir en array et arrondir
      const results = Array.from(values).map(val => Math.max(0, Math.round(val)));
      
      return results;
    } catch (error) {
      console.error('‚ùå Erreur batch prediction:', error);
      // Fallback vers pr√©dictions s√©quentielles
      console.warn('‚ö†Ô∏è Fallback vers pr√©dictions s√©quentielles');
      const results = [];
      for (const features of featuresArray) {
        try {
          const prediction = await this.predict(features);
          results.push(prediction);
        } catch (err) {
          console.error('‚ùå Erreur pr√©diction individuelle:', err);
          results.push(0);
        }
      }
      return results;
    }
  }

  /**
   * Sauvegarde le mod√®le en local storage
   * @param {string} name - Nom du mod√®le
   */
  async save(name = 'demand-forecast-model') {
    if (!this.model) {
      throw new Error('Aucun mod√®le √† sauvegarder');
    }

    console.log(`üíæ Sauvegarde du mod√®le "${name}"...`);
    
    // Sauvegarder le mod√®le
    await this.model.save(`localstorage://${name}`);
    
    // Sauvegarder les stats de normalisation
    localStorage.setItem(`${name}-stats`, JSON.stringify(this.featureStats));
    
    console.log('‚úÖ Mod√®le sauvegard√©');
  }

  /**
   * Charge un mod√®le depuis le local storage
   * @param {string} name - Nom du mod√®le
   */
  async load(name = 'demand-forecast-model') {
    console.log(`üìÇ Chargement du mod√®le "${name}"...`);
    
    try {
      // Charger le mod√®le
      this.model = await tf.loadLayersModel(`localstorage://${name}`);
      
      // Charger les stats
      const statsJson = localStorage.getItem(`${name}-stats`);
      if (statsJson) {
        this.featureStats = JSON.parse(statsJson);
      }
      
      console.log('‚úÖ Mod√®le charg√©');
      return true;
      
    } catch (error) {
      console.log('‚ÑπÔ∏è Aucun mod√®le sauvegard√© trouv√©');
      return false;
    }
  }

  /**
   * V√©rifie si un mod√®le est charg√©
   */
  isReady() {
    return this.model !== null;
  }

  /**
   * Nettoie le mod√®le de la m√©moire
   */
  dispose() {
    if (this.model) {
      this.model.dispose();
      this.model = null;
      this.featureStats = null;
      console.log('üóëÔ∏è Mod√®le nettoy√© de la m√©moire');
    }
  }
}

