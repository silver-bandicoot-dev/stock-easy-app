/**
 * Syst√®me de cache pour les calculs ML
 * Am√©liore drastiquement les performances en √©vitant les recalculs
 * @module services/ml/mlCache
 */

const DEFAULT_TTL = 5 * 60 * 1000; // 5 minutes par d√©faut
const MAX_CACHE_SIZE = 100; // Maximum 100 entr√©es en cache

class MLCache {
  constructor() {
    this.cache = new Map();
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      clears: 0
    };
  }

  /**
   * G√©n√®re une cl√© de cache √† partir des param√®tres
   * @param {string} operation - Type d'op√©ration (ex: 'revenue', 'forecast')
   * @param {Object} params - Param√®tres de l'op√©ration
   * @returns {string} Cl√© de cache
   */
  generateKey(operation, params) {
    // Cr√©er une cl√© stable √† partir des param√®tres
    const keyParts = [operation];
    
    if (params.products) {
      // Utiliser les SKUs pour identifier les produits
      const skus = Array.isArray(params.products) 
        ? params.products.map(p => p.sku || p.id).sort().join(',')
        : 'no-products';
      keyParts.push(`products:${skus}`);
    }
    
    if (params.forecastDays) {
      keyParts.push(`days:${params.forecastDays}`);
    }
    
    if (params.useMLPredictions !== undefined) {
      keyParts.push(`ml:${params.useMLPredictions}`);
    }
    
    if (params.useSeasonality !== undefined) {
      keyParts.push(`season:${params.useSeasonality}`);
    }
    
    // Hash simple pour √©viter les cl√©s trop longues
    const keyString = keyParts.join('|');
    return this.hashString(keyString);
  }

  /**
   * Hash simple d'une string
   * @private
   */
  hashString(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32bit integer
    }
    return `ml_${Math.abs(hash)}`;
  }

  /**
   * R√©cup√®re une valeur du cache
   * @param {string} key - Cl√© de cache
   * @returns {Object|null} Valeur en cache ou null
   */
  get(key) {
    const entry = this.cache.get(key);
    
    if (!entry) {
      this.stats.misses++;
      return null;
    }
    
    // V√©rifier l'expiration
    if (Date.now() > entry.expiresAt) {
      this.cache.delete(key);
      this.stats.misses++;
      return null;
    }
    
    this.stats.hits++;
    return entry.value;
  }

  /**
   * Stocke une valeur dans le cache
   * @param {string} key - Cl√© de cache
   * @param {*} value - Valeur √† stocker
   * @param {number} ttl - Time to live en millisecondes
   */
  set(key, value, ttl = DEFAULT_TTL) {
    // Nettoyer le cache si trop plein
    if (this.cache.size >= MAX_CACHE_SIZE) {
      this.cleanup();
    }
    
    const entry = {
      value,
      expiresAt: Date.now() + ttl,
      createdAt: Date.now()
    };
    
    this.cache.set(key, entry);
    this.stats.sets++;
  }

  /**
   * Nettoie le cache (supprime les entr√©es expir√©es et les plus anciennes)
   * @private
   */
  cleanup() {
    const now = Date.now();
    const expired = [];
    const entries = [];
    
    // Identifier les entr√©es expir√©es et collecter les autres
    for (const [key, entry] of this.cache.entries()) {
      if (now > entry.expiresAt) {
        expired.push(key);
      } else {
        entries.push({ key, createdAt: entry.createdAt });
      }
    }
    
    // Supprimer les expir√©es
    expired.forEach(key => this.cache.delete(key));
    
    // Si toujours trop plein, supprimer les plus anciennes
    if (this.cache.size >= MAX_CACHE_SIZE) {
      entries.sort((a, b) => a.createdAt - b.createdAt);
      const toRemove = entries.slice(0, this.cache.size - MAX_CACHE_SIZE + 10);
      toRemove.forEach(({ key }) => this.cache.delete(key));
    }
  }

  /**
   * Vide compl√®tement le cache
   */
  clear() {
    this.cache.clear();
    this.stats.clears++;
    console.log('üóëÔ∏è Cache ML vid√©');
  }

  /**
   * Supprime une entr√©e sp√©cifique
   * @param {string} key - Cl√© √† supprimer
   */
  delete(key) {
    this.cache.delete(key);
  }

  /**
   * R√©cup√®re les statistiques du cache
   * @returns {Object} Statistiques
   */
  getStats() {
    const total = this.stats.hits + this.stats.misses;
    const hitRate = total > 0 ? (this.stats.hits / total * 100).toFixed(1) : 0;
    
    return {
      size: this.cache.size,
      maxSize: MAX_CACHE_SIZE,
      hits: this.stats.hits,
      misses: this.stats.misses,
      hitRate: `${hitRate}%`,
      sets: this.stats.sets,
      clears: this.stats.clears,
      entries: Array.from(this.cache.keys())
    };
  }

  /**
   * Wrapper pour une fonction avec cache automatique
   * @param {string} operation - Type d'op√©ration
   * @param {Function} fn - Fonction √† wrapper
   * @param {Object} params - Param√®tres pour la fonction et le cache
   * @param {number} ttl - Time to live en millisecondes
   * @returns {Promise<*>} R√©sultat de la fonction (depuis cache ou calcul)
   */
  async cached(operation, fn, params = {}, ttl = DEFAULT_TTL) {
    const key = this.generateKey(operation, params);
    const cached = this.get(key);
    
    if (cached !== null) {
      console.log(`‚úÖ Cache hit for ${operation}`);
      return cached;
    }
    
    console.log(`üîÑ Cache miss for ${operation}, calculating...`);
    const start = performance.now();
    
    try {
      const result = await fn();
      const duration = performance.now() - start;
      
      this.set(key, result, ttl);
      console.log(`‚úÖ ${operation} calculated in ${duration.toFixed(0)}ms`);
      
      return result;
    } catch (error) {
      console.error(`‚ùå Error in cached ${operation}:`, error);
      throw error;
    }
  }
}

// Export d'une instance singleton
export const mlCache = new MLCache();

